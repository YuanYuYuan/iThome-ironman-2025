
# Zenoh 的 Rust 非同步 Runtime 抉擇之路

在 Zenoh 的發展過程中，我們曾經深入比較過幾個 Rust 的非同步框架。結果很有意思：**async-std** 在延遲和吞吐量上表現最好，甚至壓過了 **Tokio** 和 **smol**。特別是在 CPU 密集或網路競爭激烈的情境下，差距就更明顯。想看當年的完整報告，可以翻這篇 [官方部落格](https://zenoh.io/blog/2022-04-14-rust-async-eval/)。

---

## 為什麼要做這個測試？

Zenoh 本身就是用 Rust 開發的，我們的目標很明確：
要做到 **超低延遲** 與 **高吞吐量** 的通訊能力，非同步框架就是最關鍵的基礎之一。

---

## 測試怎麼做？

我們設計了一組 **ping-pong 應用程式**，用來量測 RTT（Round-Trip Time，往返延遲）。測試環境包含 localhost 以及 100GbE 網路，情境有純網路負載，也有混合計算負載，模擬 Zenoh 實際運行時上千個 session 并行的情況。

---

## 當年的測試結果

* **async-std** 與 **smol** 在不少情境下，都能打平甚至超越標準函式庫。
* **Tokio** 的延遲相對高，在 CPU-bound 的非同步任務裡，往往多出 8–10 微秒。
* 當時我們因此傾向於 **繼續用 async-std**，因為它的表現最穩定。但心裡也清楚，Rust 的非同步生態還在演化，需要社群一起推進。

---

## 更新測試：在我的筆電上跑

最近我用更新後的 [net-benchmark](https://github.com/YuanYuYuan/net-benchmark) 腳本，在自己的筆電上又跑了一輪測試。

結果怎麼樣？答案是：**結論依然差不多！**
async-std 依舊在高頻場景下壓過 tokio。

---

## 測試工具介紹

這個基準測試工具是一個 **統一的 ping-pong 測試器**，支援 `async-std`、`Tokio`、`smol` 和 `std`。可以測 **TCP/UDP** 的 RTT，還能調整封包大小與間隔。

亮點功能：

* 可選 runtime 後端（`--backend tokio|async-std|smol|std`）
* 支援 TCP/UDP 的 ping-pong 模式
* 封包大小、間隔、測試時間都能自訂
* 可以輸出 CSV，方便後續分析

---

### Ping 與 Pong 怎麼跑？

* **Pong（接收端）**

  * 綁定在某個位址，等待連線
  * 收到資料就馬上回傳
  * 透過選定的 runtime（或標準執行緒）支援多連線

* **Ping（發送端）**

  * 主動連線到 pong
  * 定時送出封包並量測 RTT
  * 測試持續到指定時間，然後輸出所有樣本
  * 使用原子旗標 + 計時器，嚴格控制測試流程

設計很單純，但能把不同 runtime 的差異放大看得一清二楚。

---

### 使用範例

```bash
# 跑一個 async-std 的 TCP pong 伺服器
cargo run -- --mode pong --protocol tcp --backend async-std --address 127.0.0.1:5555 --size 64

# 跑一個 async-std 的 TCP ping 客戶端
cargo run -- --mode ping --protocol tcp --backend async-std --address 127.0.0.1:5555 --size 64 --interval 0.001 --duration 10
```

---

### 範例程式碼片段（Tokio TCP Ping）

```rust
let now = Instant::now();
stream.write_all(&payload).await.unwrap();
stream.read_exact(&mut payload).await.unwrap();
let elapsed = now.elapsed();
samples.push(elapsed);
```

核心流程：

1. 記下開始時間
2. 傳封包
3. 收回 echo
4. 記錄耗時

---

### 測試結果

以下是 **64-byte 封包** 的中位數 RTT：

| 頻率標籤   | async-std |   smol |    std |  tokio |
| :----- | --------: | -----: | -----: | -----: |
| 10 Hz  |    340.75 | 317.84 | 229.98 | 296.08 |
| 100 Hz |    239.11 | 243.60 | 238.42 | 265.34 |
| 1 KHz  |     31.42 |  31.14 |  25.43 | 112.44 |
| 10 KHz |     22.30 |  23.77 |  23.37 |  36.18 |
| 無限 Hz  |     14.43 |  14.33 |  11.00 |  35.31 |

![comparison](https://raw.githubusercontent.com/YuanYuYuan/net-benchmark/refs/heads/main/asset/comparison.png)

觀察下來：即使在一台普通筆電上，**async-std 和 smol 在高頻場景下延遲依然更低**；而 Tokio RTT 偏高，跟之前的測試一致。

---

## 那為什麼 Zenoh 最後還是選擇 Tokio？

儘管 async-std 在數據上很漂亮，但最終我們還是改用了 **Tokio**。原因很務實：

1. **維護性**：async-std 已經不再積極維護，長期可靠性是個隱憂。
2. **生態系**：Tokio 有完整的函式庫與龐大社群，找套件幾乎不用愁。
3. **可客製化**：Tokio 的 runtime 行為可以細調（執行緒數、排程策略、阻塞處理），這點我們在前一篇文章深入介紹過。
4. **效能**：在低頻情境下，Tokio 的表現其實和其他框架差不多。
